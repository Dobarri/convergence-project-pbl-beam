{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-07T11:19:05.781886Z","iopub.execute_input":"2023-04-07T11:19:05.782371Z","iopub.status.idle":"2023-04-07T11:19:05.791922Z","shell.execute_reply.started":"2023-04-07T11:19:05.782322Z","shell.execute_reply":"2023-04-07T11:19:05.790838Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:19:05.796850Z","iopub.execute_input":"2023-04-07T11:19:05.797527Z","iopub.status.idle":"2023-04-07T11:19:05.809998Z","shell.execute_reply.started":"2023-04-07T11:19:05.797492Z","shell.execute_reply":"2023-04-07T11:19:05.809053Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"!wget -O /kaggle/working/Vision.zip \"https://www.dropbox.com/s/mamwc19rgy8wiv5/Vision.zip?dl=1\"","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:19:05.811883Z","iopub.execute_input":"2023-04-07T11:19:05.813221Z","iopub.status.idle":"2023-04-07T11:19:35.142328Z","shell.execute_reply.started":"2023-04-07T11:19:05.813185Z","shell.execute_reply":"2023-04-07T11:19:35.141071Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"--2023-04-07 11:19:07--  https://www.dropbox.com/s/mamwc19rgy8wiv5/Vision.zip?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/dl/mamwc19rgy8wiv5/Vision.zip [following]\n--2023-04-07 11:19:07--  https://www.dropbox.com/s/dl/mamwc19rgy8wiv5/Vision.zip\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com/cd/0/get/B5tvXb24eZQeUG_9d42AwtNsLfLRHfJ1iroscOBFb8aHJpJpzNOK0rJEWY2blH8utKnEJI0A0j0aZaL0qxbJPuatdiyvcxAe3bg0aJdHgZCtjWdxI5C_u4RK8nB5DJnXX3g-0wmENqMBeAyzRUmVtRyk_TScxEMezL3sfSUYzPmgPAnuTOMfVwyO9Q7Xbqrx17E/file?dl=1# [following]\n--2023-04-07 11:19:08--  https://uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com/cd/0/get/B5tvXb24eZQeUG_9d42AwtNsLfLRHfJ1iroscOBFb8aHJpJpzNOK0rJEWY2blH8utKnEJI0A0j0aZaL0qxbJPuatdiyvcxAe3bg0aJdHgZCtjWdxI5C_u4RK8nB5DJnXX3g-0wmENqMBeAyzRUmVtRyk_TScxEMezL3sfSUYzPmgPAnuTOMfVwyO9Q7Xbqrx17E/file?dl=1\nResolving uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com (uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\nConnecting to uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com (uc2ad96a0d26239b7304978b173b.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3359796705 (3.1G) [application/binary]\nSaving to: ‘/kaggle/working/Vision.zip’\n\n/kaggle/working/Vis 100%[===================>]   3.13G   130MB/s    in 26s     \n\n2023-04-07 11:19:34 (122 MB/s) - ‘/kaggle/working/Vision.zip’ saved [3359796705/3359796705]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip Vision.zip -d \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:19:35.144025Z","iopub.execute_input":"2023-04-07T11:19:35.145304Z","iopub.status.idle":"2023-04-07T11:21:17.994578Z","shell.execute_reply.started":"2023-04-07T11:19:35.145257Z","shell.execute_reply":"2023-04-07T11:21:17.993282Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Archive:  Vision.zip\nreplace /kaggle/working/Vision/Scenario5/challenge_dataset/scenario5_challenge.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# define root directory\nROOT = os.getcwd()\nprint(ROOT)\n\ndataset_dir = os.path.join(ROOT,\"Vision\")\nscenario_dir = os.path.join(dataset_dir,\"Scenario7\")\ndevelopment_dir = os.path.join(scenario_dir, \"development_dataset\")\nchallenge_dir = os.path.join(scenario_dir, \"challenge_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:19.965619Z","iopub.execute_input":"2023-04-07T11:21:19.966327Z","iopub.status.idle":"2023-04-07T11:21:19.974011Z","shell.execute_reply.started":"2023-04-07T11:21:19.966289Z","shell.execute_reply":"2023-04-07T11:21:19.972684Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"path = '/kaggle/working/Vision'\ncheckpoint = 'checkpoint'\n\nfor p in os.listdir(path) :\n    os.mkdir(os.path.join(path,p,checkpoint))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:20.149196Z","iopub.execute_input":"2023-04-07T11:21:20.150416Z","iopub.status.idle":"2023-04-07T11:21:20.169941Z","shell.execute_reply.started":"2023-04-07T11:21:20.150375Z","shell.execute_reply":"2023-04-07T11:21:20.168393Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_260/844686648.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/kaggle/working/Vision/Scenario8/checkpoint'"],"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/kaggle/working/Vision/Scenario8/checkpoint'","output_type":"error"}]},{"cell_type":"code","source":"import random\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available() :\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:20.292251Z","iopub.execute_input":"2023-04-07T11:21:20.292655Z","iopub.status.idle":"2023-04-07T11:21:20.377969Z","shell.execute_reply.started":"2023-04-07T11:21:20.292602Z","shell.execute_reply":"2023-04-07T11:21:20.376892Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# load data\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms.functional as FT\n\ndef transform(image, flag) :\n    mean = [0.485, 0.456, 0.406]\n    std =  [0.229, 0.224, 0.225]\n\n    if flag == 2 :      #test\n        new_image = FT.resize(image,224)\n        new_image = FT.to_tensor(new_image)\n        new_image = FT.normalize(new_image, mean=mean, std=std)\n    else :              #train, val\n        new_image = FT.resize(image,224)\n        new_image = FT.to_tensor(new_image)\n        new_image = FT.normalize(new_image, mean=mean, std=std)\n\n    return new_image\n\nclass DeepSense6G(Dataset):\n    def __init__(self, data_folder, split, flag):\n        self.split = split\n        assert self.split in {'Scenario5','Scenario6','Scenario7','Scenario8','Scenario9'}\n\n        self.data_folder = data_folder\n        self.scenario_path = os.path.join(self.data_folder, split)\n        self.development_path = os.path.join(self.scenario_path, 'development_dataset')\n        self.challenge_path = os.path.join(self.scenario_path, 'challenge_dataset')\n\n        self.flag = flag\n\n        self.split = self.split.lower()\n        if flag == 0 :      #train\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_train.csv')\n        elif flag == 1 :    #validation\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_val.csv')\n        elif flag == 2 :              #test\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_test.csv')\n\n        self.dataframe = pd.read_csv(self.dataframe_path)\n\n        self.Images_path = self.dataframe['unit1_rgb_1'].values\n        self.Beam_index = self.dataframe['beam_index_1'].values\n        self.image_index = self.dataframe['index'].values\n        self.Beam_pwr_path = self.dataframe['unit1_pwr_1'].values\n\n    def __getitem__(self, i):\n\n        self.img_rel_path = self.Images_path[i]\n\n        if self.flag == 2 :     #test\n            self.img_abs_path = os.path.join(self.development_path, self.img_rel_path)\n        else :                  #train, validation\n            self.img_abs_path = os.path.join(self.development_path, self.img_rel_path)\n        \n        image = Image.open(self.img_abs_path, mode='r')\n        image = image.convert('RGB')\n\n        beam_index = self.Beam_index[i]\n\n        image = transform(image, self.flag)\n\n        return image, beam_index\n\n    def __len__(self):\n        return len(self.Images_path)\n\n    # def _collate_fn(self, batch_size) :\n\n    #     images = list()\n    #     beam_indexes = list()\n\n    #     for b in batch_size :\n    #         images.append(b[0])\n    #         beam_indexes.append(b[1])\n\n    #     images = torch.stack(images, dim=0)\n\n    #     return images, beam_indexes","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:20.454027Z","iopub.execute_input":"2023-04-07T11:21:20.456295Z","iopub.status.idle":"2023-04-07T11:21:20.828953Z","shell.execute_reply.started":"2023-04-07T11:21:20.456254Z","shell.execute_reply":"2023-04-07T11:21:20.827907Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# device initialize\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:20.830670Z","iopub.execute_input":"2023-04-07T11:21:20.831304Z","iopub.status.idle":"2023-04-07T11:21:20.840672Z","shell.execute_reply.started":"2023-04-07T11:21:20.831264Z","shell.execute_reply":"2023-04-07T11:21:20.839311Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## wideResnet101","metadata":{}},{"cell_type":"code","source":"#wide_resnet101_2\n\nwide_resnet101 = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\nnum_ftrs = wide_resnet101.fc.in_features\nwide_resnet101.fc = torch.nn.Linear(num_ftrs, 64)\n\nmodel = wide_resnet101.to(DEVICE)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:20.949456Z","iopub.execute_input":"2023-04-07T11:21:20.950218Z","iopub.status.idle":"2023-04-07T11:21:28.677321Z","shell.execute_reply.started":"2023-04-07T11:21:20.950170Z","shell.execute_reply":"2023-04-07T11:21:28.676182Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet101_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet101_2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=64, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#training\nimport time\n\nbatch_size = 32\nscenario = 'Scenario7'\n\ntrain_dataset = DeepSense6G(dataset_dir, split=scenario, flag=0)\nval_dataset = DeepSense6G(dataset_dir, split=scenario, flag=1)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False) \n\nepochs = 30\nbest_loss = 100\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12,20], gamma=0.2)\nloss = torch.nn.CrossEntropyLoss().cuda()\n\ntrain_acc_list = []\nval_acc_list = []\nlrs = []\n\nfor epoch in range(epochs) :\n    start = time.time()\n    print(f'Epoch {epoch}/{epochs}')\n\n    #train\n    train_loss = 0\n    correct = 0\n\n    model.train()\n    for img, bi in tqdm(train_loader) :\n\n        optimizer.zero_grad()\n        y_pred = model(img.cuda())\n        cost = loss(y_pred, bi.cuda())\n\n        cost.backward()\n        optimizer.step()\n        lrs.append(optimizer.param_groups[0][\"lr\"])\n        scheduler.step()\n        \n        train_loss += cost.item()\n\n        pred = y_pred.data.max(1, keepdim=True)[1]\n        correct += pred.cpu().eq(bi.data.view_as(pred)).sum()\n\n    train_loss /= len(train_loader)\n    train_acc = correct / len(train_loader.dataset)\n    train_acc_list.append(train_acc)\n\n    #validate\n    val_loss = 0\n    val_correct = 0\n\n    with torch.no_grad() :\n        model.eval()\n        for img, bi in val_loader :\n            y_pred = model(img.cuda())\n            cost = loss(y_pred, bi.cuda())\n            val_loss += cost.item()\n\n            pred = y_pred.data.max(1, keepdim=True)[1]\n            val_correct += pred.cpu().eq(bi.data.view_as(pred)).cpu().sum()\n        \n        val_loss /= len(val_loader)\n        val_acc = val_correct / len(val_loader.dataset)\n        val_acc_list.append(val_acc)\n\n        if val_loss < best_loss :\n            torch.save({\n                'epoch' : epoch,\n                'model' : model,\n                'model_state_dict' : model.state_dict(),\n                'optimizer_state_dict' : optimizer.state_dict(),\n                'loss' : cost.item,\n            }, os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))\n\n            print(f'Epoch {epoch:05d}: val_loss improved from {best_loss:.5f} to {val_loss:.5f}, saving model to bestCheckPoint.pth')\n            best_loss = val_loss\n        else :\n            print(f'Epoch {epoch:05d}: val_loss did not improve')\n    print(f'{int(time.time() - start)}s - loss: {train_loss: .5f} - acc: {train_acc:.5f} - val_loss: {val_loss:.5f} - val_acc: {val_acc:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:21:28.679582Z","iopub.execute_input":"2023-04-07T11:21:28.680273Z","iopub.status.idle":"2023-04-07T11:44:13.066393Z","shell.execute_reply.started":"2023-04-07T11:21:28.680231Z","shell.execute_reply":"2023-04-07T11:44:13.065353Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 0/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:38<00:00,  2.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00000: val_loss improved from 100.00000 to 3.74472, saving model to bestCheckPoint.pth\n50s - loss:  3.88571 - acc: 0.10035 - val_loss: 3.74472 - val_acc: 0.17838\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00001: val_loss improved from 3.74472 to 3.63609, saving model to bestCheckPoint.pth\n46s - loss:  3.35066 - acc: 0.22887 - val_loss: 3.63609 - val_acc: 0.18919\nEpoch 2/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00002: val_loss improved from 3.63609 to 3.57407, saving model to bestCheckPoint.pth\n45s - loss:  3.23555 - acc: 0.27641 - val_loss: 3.57407 - val_acc: 0.18919\nEpoch 3/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00003: val_loss improved from 3.57407 to 3.50653, saving model to bestCheckPoint.pth\n45s - loss:  3.12368 - acc: 0.30810 - val_loss: 3.50653 - val_acc: 0.20541\nEpoch 4/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00004: val_loss improved from 3.50653 to 3.44522, saving model to bestCheckPoint.pth\n45s - loss:  3.02314 - acc: 0.33627 - val_loss: 3.44522 - val_acc: 0.22703\nEpoch 5/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00005: val_loss improved from 3.44522 to 3.38922, saving model to bestCheckPoint.pth\n45s - loss:  2.92340 - acc: 0.40493 - val_loss: 3.38922 - val_acc: 0.23243\nEpoch 6/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00006: val_loss improved from 3.38922 to 3.33045, saving model to bestCheckPoint.pth\n45s - loss:  2.81896 - acc: 0.42606 - val_loss: 3.33045 - val_acc: 0.24324\nEpoch 7/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00007: val_loss improved from 3.33045 to 3.26966, saving model to bestCheckPoint.pth\n45s - loss:  2.71649 - acc: 0.48063 - val_loss: 3.26966 - val_acc: 0.25405\nEpoch 8/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00008: val_loss improved from 3.26966 to 3.22682, saving model to bestCheckPoint.pth\n45s - loss:  2.61356 - acc: 0.50176 - val_loss: 3.22682 - val_acc: 0.26486\nEpoch 9/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00009: val_loss improved from 3.22682 to 3.17785, saving model to bestCheckPoint.pth\n45s - loss:  2.52078 - acc: 0.51232 - val_loss: 3.17785 - val_acc: 0.28108\nEpoch 10/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00010: val_loss improved from 3.17785 to 3.12886, saving model to bestCheckPoint.pth\n45s - loss:  2.43711 - acc: 0.52113 - val_loss: 3.12886 - val_acc: 0.28108\nEpoch 11/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00011: val_loss improved from 3.12886 to 3.09625, saving model to bestCheckPoint.pth\n45s - loss:  2.34218 - acc: 0.56866 - val_loss: 3.09625 - val_acc: 0.29189\nEpoch 12/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00012: val_loss improved from 3.09625 to 3.05379, saving model to bestCheckPoint.pth\n45s - loss:  2.24274 - acc: 0.58979 - val_loss: 3.05379 - val_acc: 0.28649\nEpoch 13/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00013: val_loss improved from 3.05379 to 3.01728, saving model to bestCheckPoint.pth\n45s - loss:  2.18265 - acc: 0.60563 - val_loss: 3.01728 - val_acc: 0.29189\nEpoch 14/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00014: val_loss improved from 3.01728 to 2.99348, saving model to bestCheckPoint.pth\n45s - loss:  2.08449 - acc: 0.64261 - val_loss: 2.99348 - val_acc: 0.30270\nEpoch 15/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00015: val_loss improved from 2.99348 to 2.95080, saving model to bestCheckPoint.pth\n45s - loss:  2.01757 - acc: 0.64261 - val_loss: 2.95080 - val_acc: 0.28108\nEpoch 16/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00016: val_loss improved from 2.95080 to 2.92604, saving model to bestCheckPoint.pth\n45s - loss:  1.92956 - acc: 0.69542 - val_loss: 2.92604 - val_acc: 0.29189\nEpoch 17/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00017: val_loss improved from 2.92604 to 2.90126, saving model to bestCheckPoint.pth\n45s - loss:  1.84219 - acc: 0.70423 - val_loss: 2.90126 - val_acc: 0.27568\nEpoch 18/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00018: val_loss improved from 2.90126 to 2.87199, saving model to bestCheckPoint.pth\n45s - loss:  1.77060 - acc: 0.71831 - val_loss: 2.87199 - val_acc: 0.29189\nEpoch 19/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00019: val_loss improved from 2.87199 to 2.85657, saving model to bestCheckPoint.pth\n45s - loss:  1.69638 - acc: 0.73063 - val_loss: 2.85657 - val_acc: 0.28108\nEpoch 20/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00020: val_loss improved from 2.85657 to 2.83922, saving model to bestCheckPoint.pth\n45s - loss:  1.62944 - acc: 0.74648 - val_loss: 2.83922 - val_acc: 0.29189\nEpoch 21/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00021: val_loss improved from 2.83922 to 2.80926, saving model to bestCheckPoint.pth\n45s - loss:  1.56656 - acc: 0.75176 - val_loss: 2.80926 - val_acc: 0.28649\nEpoch 22/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00022: val_loss improved from 2.80926 to 2.78997, saving model to bestCheckPoint.pth\n45s - loss:  1.50715 - acc: 0.77465 - val_loss: 2.78997 - val_acc: 0.29189\nEpoch 23/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00023: val_loss improved from 2.78997 to 2.76625, saving model to bestCheckPoint.pth\n45s - loss:  1.46348 - acc: 0.78697 - val_loss: 2.76625 - val_acc: 0.29189\nEpoch 24/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00024: val_loss did not improve\n42s - loss:  1.38495 - acc: 0.79930 - val_loss: 2.77208 - val_acc: 0.28649\nEpoch 25/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.83s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00025: val_loss improved from 2.76625 to 2.74106, saving model to bestCheckPoint.pth\n45s - loss:  1.32485 - acc: 0.81866 - val_loss: 2.74106 - val_acc: 0.30270\nEpoch 26/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.85s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00026: val_loss improved from 2.74106 to 2.73969, saving model to bestCheckPoint.pth\n45s - loss:  1.26276 - acc: 0.82394 - val_loss: 2.73969 - val_acc: 0.29730\nEpoch 27/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00027: val_loss improved from 2.73969 to 2.71806, saving model to bestCheckPoint.pth\n45s - loss:  1.21914 - acc: 0.83099 - val_loss: 2.71806 - val_acc: 0.29189\nEpoch 28/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.84s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00028: val_loss improved from 2.71806 to 2.70246, saving model to bestCheckPoint.pth\n45s - loss:  1.15516 - acc: 0.84683 - val_loss: 2.70246 - val_acc: 0.30811\nEpoch 29/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:33<00:00,  1.86s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00029: val_loss improved from 2.70246 to 2.69710, saving model to bestCheckPoint.pth\n45s - loss:  1.09788 - acc: 0.87676 - val_loss: 2.69710 - val_acc: 0.30811\n","output_type":"stream"}]},{"cell_type":"code","source":"## 저장되어있는 best checkpoint load\n\nbest_model = torch.load(os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))['model'] \nbest_model.load_state_dict(torch.load(os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))['model_state_dict'])  ","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:44:13.069108Z","iopub.execute_input":"2023-04-07T11:44:13.069822Z","iopub.status.idle":"2023-04-07T11:44:15.131699Z","shell.execute_reply.started":"2023-04-07T11:44:13.069780Z","shell.execute_reply":"2023-04-07T11:44:15.130696Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"#test \nimport math\n\nbatch_size = 1\n\ntest_dataset = DeepSense6G(dataset_dir, split=scenario, flag=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\ncorrect = 0\ntotal = 0\ntotal_results = []\ngt = []\n\ndef top_k (gts, preds, k) :\n    correct = 0\n\n    for i in range(len(preds)) :\n        gt = gts[i]\n        pred = preds[i]\n        correct += int(gt.item() in pred[:k])\n    \n    print(scenario, 'top', k, 'accuracy', 100 * correct / len(preds))\n\ndef mse (gts, preds) :\n    mse = 0\n\n    for i in range(len(preds)) :\n        gt = gts[i].item()\n        pred = preds[i][0]\n        mse += math.sqrt((gt-pred)**2)\n    \n    print(scenario, 'mse', mse/len(preds))\n\nwith torch.no_grad() :\n    model.eval()\n    for img, bi in test_loader :\n        pred = best_model(img.cuda())\n        sorted_result_idx = np.flip(np.array(np.argsort(pred.cpu())[0]))\n        top3 = sorted_result_idx[:3]\n        total_results.append(top3)\n        gt.append(bi)\n\ntop_k(gt, total_results, 1)\ntop_k(gt, total_results, 2)\ntop_k(gt, total_results, 3)\nmse(gt, total_results)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T11:44:15.134178Z","iopub.execute_input":"2023-04-07T11:44:15.134556Z","iopub.status.idle":"2023-04-07T11:44:26.243383Z","shell.execute_reply.started":"2023-04-07T11:44:15.134518Z","shell.execute_reply":"2023-04-07T11:44:26.242316Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Scenario7 top 1 accuracy 39.80582524271845\nScenario7 top 2 accuracy 61.16504854368932\nScenario7 top 3 accuracy 66.99029126213593\nScenario7 mse 1.2524271844660195\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}