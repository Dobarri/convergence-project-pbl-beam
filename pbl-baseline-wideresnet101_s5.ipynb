{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-07T06:49:48.894291Z","iopub.execute_input":"2023-04-07T06:49:48.895422Z","iopub.status.idle":"2023-04-07T06:49:48.903188Z","shell.execute_reply.started":"2023-04-07T06:49:48.895349Z","shell.execute_reply":"2023-04-07T06:49:48.901931Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:49:48.908843Z","iopub.execute_input":"2023-04-07T06:49:48.909504Z","iopub.status.idle":"2023-04-07T06:49:48.920843Z","shell.execute_reply.started":"2023-04-07T06:49:48.909472Z","shell.execute_reply":"2023-04-07T06:49:48.919770Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"!wget -O /kaggle/working/Vision.zip \"https://www.dropbox.com/s/mamwc19rgy8wiv5/Vision.zip?dl=1\"","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:49:48.923232Z","iopub.execute_input":"2023-04-07T06:49:48.923818Z","iopub.status.idle":"2023-04-07T06:50:32.333631Z","shell.execute_reply.started":"2023-04-07T06:49:48.923770Z","shell.execute_reply":"2023-04-07T06:50:32.332317Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"--2023-04-07 06:49:49--  https://www.dropbox.com/s/mamwc19rgy8wiv5/Vision.zip?dl=1\nResolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/dl/mamwc19rgy8wiv5/Vision.zip [following]\n--2023-04-07 06:49:50--  https://www.dropbox.com/s/dl/mamwc19rgy8wiv5/Vision.zip\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com/cd/0/get/B5tKisE1HS58KXQF6UTLxPgk1tWLgw9odDe4VIeUJW9VxRfLL-I96do8Ep7G5yW4ob-KP8zizBi3h0qD53nSjSSGZMIiLf3PzBeGRwXk0gbJ-MTYZwVcQCSml_6ez49YeCjiUTXPLWVS9CH_B41tBuR6zgY1O23Cxth0vKuyfTfyfamcu8-cfIfRiLRnehzyf7s/file?dl=1# [following]\n--2023-04-07 06:49:50--  https://ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com/cd/0/get/B5tKisE1HS58KXQF6UTLxPgk1tWLgw9odDe4VIeUJW9VxRfLL-I96do8Ep7G5yW4ob-KP8zizBi3h0qD53nSjSSGZMIiLf3PzBeGRwXk0gbJ-MTYZwVcQCSml_6ez49YeCjiUTXPLWVS9CH_B41tBuR6zgY1O23Cxth0vKuyfTfyfamcu8-cfIfRiLRnehzyf7s/file?dl=1\nResolving ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com (ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\nConnecting to ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com (ucc9499c3379470bbd186e0faf40.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3359796705 (3.1G) [application/binary]\nSaving to: ‘/kaggle/working/Vision.zip’\n\n/kaggle/working/Vis 100%[===================>]   3.13G  46.1MB/s    in 40s     \n\n2023-04-07 06:50:31 (79.7 MB/s) - ‘/kaggle/working/Vision.zip’ saved [3359796705/3359796705]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip Vision.zip -d \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:50:32.337581Z","iopub.execute_input":"2023-04-07T06:50:32.337920Z","iopub.status.idle":"2023-04-07T06:57:59.139263Z","shell.execute_reply.started":"2023-04-07T06:50:32.337884Z","shell.execute_reply":"2023-04-07T06:57:59.137905Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Archive:  Vision.zip\nreplace /kaggle/working/Vision/Scenario5/challenge_dataset/scenario5_challenge.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# define root directory\nROOT = os.getcwd()\nprint(ROOT)\n\ndataset_dir = os.path.join(ROOT,\"Vision\")\nscenario_dir = os.path.join(dataset_dir,\"Scenario5\")\ndevelopment_dir = os.path.join(scenario_dir, \"development_dataset\")\nchallenge_dir = os.path.join(scenario_dir, \"challenge_dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:00.453154Z","iopub.execute_input":"2023-04-07T06:58:00.453905Z","iopub.status.idle":"2023-04-07T06:58:00.461260Z","shell.execute_reply.started":"2023-04-07T06:58:00.453865Z","shell.execute_reply":"2023-04-07T06:58:00.459906Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"path = '/kaggle/working/Vision'\ncheckpoint = 'checkpoint'\n\nfor p in os.listdir(path) :\n    os.mkdir(os.path.join(path,p,checkpoint))","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:00.621884Z","iopub.execute_input":"2023-04-07T06:58:00.622606Z","iopub.status.idle":"2023-04-07T06:58:00.640564Z","shell.execute_reply.started":"2023-04-07T06:58:00.622565Z","shell.execute_reply":"2023-04-07T06:58:00.639149Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1888/844686648.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/kaggle/working/Vision/Scenario6/checkpoint'"],"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/kaggle/working/Vision/Scenario6/checkpoint'","output_type":"error"}]},{"cell_type":"code","source":"import random\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\nif torch.cuda.is_available() :\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:00.750548Z","iopub.execute_input":"2023-04-07T06:58:00.751430Z","iopub.status.idle":"2023-04-07T06:58:00.832144Z","shell.execute_reply.started":"2023-04-07T06:58:00.751379Z","shell.execute_reply":"2023-04-07T06:58:00.831097Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# load data\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms.functional as FT\n\ndef transform(image, flag) :\n    mean = [0.485, 0.456, 0.406]\n    std =  [0.229, 0.224, 0.225]\n\n    if flag == 2 :      #test\n        new_image = FT.resize(image,224)\n        new_image = FT.to_tensor(new_image)\n        new_image = FT.normalize(new_image, mean=mean, std=std)\n    else :              #train, val\n        new_image = FT.resize(image,224)\n        new_image = FT.to_tensor(new_image)\n        new_image = FT.normalize(new_image, mean=mean, std=std)\n\n    return new_image\n\nclass DeepSense6G(Dataset):\n    def __init__(self, data_folder, split, flag):\n        self.split = split\n        assert self.split in {'Scenario5','Scenario6','Scenario7','Scenario8','Scenario9'}\n\n        self.data_folder = data_folder\n        self.scenario_path = os.path.join(self.data_folder, split)\n        self.development_path = os.path.join(self.scenario_path, 'development_dataset')\n        self.challenge_path = os.path.join(self.scenario_path, 'challenge_dataset')\n\n        self.flag = flag\n\n        self.split = self.split.lower()\n        if flag == 0 :      #train\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_train.csv')\n        elif flag == 1 :    #validation\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_val.csv')\n        elif flag == 2 :              #test\n            self.dataframe_path = os.path.join(self.development_path, self.split + '_dev_test.csv')\n\n        self.dataframe = pd.read_csv(self.dataframe_path)\n\n        self.Images_path = self.dataframe['unit1_rgb_1'].values\n        self.Beam_index = self.dataframe['beam_index_1'].values\n        self.image_index = self.dataframe['index'].values\n        self.Beam_pwr_path = self.dataframe['unit1_pwr_1'].values\n\n    def __getitem__(self, i):\n\n        self.img_rel_path = self.Images_path[i]\n\n        if self.flag == 2 :     #test\n            self.img_abs_path = os.path.join(self.development_path, self.img_rel_path)\n        else :                  #train, validation\n            self.img_abs_path = os.path.join(self.development_path, self.img_rel_path)\n        \n        image = Image.open(self.img_abs_path, mode='r')\n        image = image.convert('RGB')\n\n        beam_index = self.Beam_index[i]\n\n        image = transform(image, self.flag)\n\n        return image, beam_index\n\n    def __len__(self):\n        return len(self.Images_path)\n\n    # def _collate_fn(self, batch_size) :\n\n    #     images = list()\n    #     beam_indexes = list()\n\n    #     for b in batch_size :\n    #         images.append(b[0])\n    #         beam_indexes.append(b[1])\n\n    #     images = torch.stack(images, dim=0)\n\n    #     return images, beam_indexes","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:00.893653Z","iopub.execute_input":"2023-04-07T06:58:00.893994Z","iopub.status.idle":"2023-04-07T06:58:01.277068Z","shell.execute_reply.started":"2023-04-07T06:58:00.893962Z","shell.execute_reply":"2023-04-07T06:58:01.276012Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# device initialize\n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:01.279188Z","iopub.execute_input":"2023-04-07T06:58:01.279589Z","iopub.status.idle":"2023-04-07T06:58:01.285954Z","shell.execute_reply.started":"2023-04-07T06:58:01.279550Z","shell.execute_reply":"2023-04-07T06:58:01.284551Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## wideResnet101","metadata":{}},{"cell_type":"code","source":"#wide_resnet101_2\n\nwide_resnet101 = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\nnum_ftrs = wide_resnet101.fc.in_features\nwide_resnet101.fc = torch.nn.Linear(num_ftrs, 64)\n\nmodel = wide_resnet101.to(DEVICE)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:01.341496Z","iopub.execute_input":"2023-04-07T06:58:01.341818Z","iopub.status.idle":"2023-04-07T06:58:08.053464Z","shell.execute_reply.started":"2023-04-07T06:58:01.341782Z","shell.execute_reply":"2023-04-07T06:58:08.052340Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet101_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet101_2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=64, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"#training\nimport time\n\nbatch_size = 32\nscenario = 'Scenario5'\n\ntrain_dataset = DeepSense6G(dataset_dir, split=scenario, flag=0)\nval_dataset = DeepSense6G(dataset_dir, split=scenario, flag=1)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False) \n\nepochs = 30\nbest_loss = 100\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[12,20], gamma=0.2)\nloss = torch.nn.CrossEntropyLoss().cuda()\n\ntrain_acc_list = []\nval_acc_list = []\nlrs = []\n\nfor epoch in range(epochs) :\n    start = time.time()\n    print(f'Epoch {epoch}/{epochs}')\n\n    #train\n    train_loss = 0\n    correct = 0\n\n    model.train()\n    for img, bi in tqdm(train_loader) :\n\n        optimizer.zero_grad()\n        y_pred = model(img.cuda())\n        cost = loss(y_pred, bi.cuda())\n\n        cost.backward()\n        optimizer.step()\n        lrs.append(optimizer.param_groups[0][\"lr\"])\n        scheduler.step()\n        \n        train_loss += cost.item()\n\n        pred = y_pred.data.max(1, keepdim=True)[1]\n        correct += pred.cpu().eq(bi.data.view_as(pred)).sum()\n\n    train_loss /= len(train_loader)\n    train_acc = correct / len(train_loader.dataset)\n    train_acc_list.append(train_acc)\n\n    #validate\n    val_loss = 0\n    val_correct = 0\n\n    with torch.no_grad() :\n        model.eval()\n        for img, bi in val_loader :\n            y_pred = model(img.cuda())\n            cost = loss(y_pred, bi.cuda())\n            val_loss += cost.item()\n\n            pred = y_pred.data.max(1, keepdim=True)[1]\n            val_correct += pred.cpu().eq(bi.data.view_as(pred)).cpu().sum()\n        \n        val_loss /= len(val_loader)\n        val_acc = val_correct / len(val_loader.dataset)\n        val_acc_list.append(val_acc)\n\n        if val_loss < best_loss :\n            torch.save({\n                'epoch' : epoch,\n                'model' : model,\n                'model_state_dict' : model.state_dict(),\n                'optimizer_state_dict' : optimizer.state_dict(),\n                'loss' : cost.item,\n            }, os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))\n\n            print(f'Epoch {epoch:05d}: val_loss improved from {best_loss:.5f} to {val_loss:.5f}, saving model to bestCheckPoint.pth')\n            best_loss = val_loss\n        else :\n            print(f'Epoch {epoch:05d}: val_loss did not improve')\n    print(f'{int(time.time() - start)}s - loss: {train_loss: .5f} - acc: {train_acc:.5f} - val_loss: {val_loss:.5f} - val_acc: {val_acc:.5f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-07T06:58:08.055692Z","iopub.execute_input":"2023-04-07T06:58:08.056389Z","iopub.status.idle":"2023-04-07T07:55:59.585478Z","shell.execute_reply.started":"2023-04-07T06:58:08.056347Z","shell.execute_reply":"2023-04-07T07:55:59.583832Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 0/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:39<00:00,  1.98s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00000: val_loss improved from 100.00000 to 3.18667, saving model to bestCheckPoint.pth\n121s - loss:  3.51576 - acc: 0.23801 - val_loss: 3.18667 - val_acc: 0.34586\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00001: val_loss improved from 3.18667 to 2.97053, saving model to bestCheckPoint.pth\n116s - loss:  3.06531 - acc: 0.34533 - val_loss: 2.97053 - val_acc: 0.37343\nEpoch 2/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00002: val_loss improved from 2.97053 to 2.73258, saving model to bestCheckPoint.pth\n115s - loss:  2.83490 - acc: 0.38194 - val_loss: 2.73258 - val_acc: 0.38095\nEpoch 3/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00003: val_loss improved from 2.73258 to 2.55029, saving model to bestCheckPoint.pth\n116s - loss:  2.62553 - acc: 0.42677 - val_loss: 2.55029 - val_acc: 0.40602\nEpoch 4/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00004: val_loss improved from 2.55029 to 2.37807, saving model to bestCheckPoint.pth\n116s - loss:  2.43083 - acc: 0.46843 - val_loss: 2.37807 - val_acc: 0.46366\nEpoch 5/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00005: val_loss improved from 2.37807 to 2.26563, saving model to bestCheckPoint.pth\n116s - loss:  2.23800 - acc: 0.52652 - val_loss: 2.26563 - val_acc: 0.48622\nEpoch 6/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00006: val_loss improved from 2.26563 to 2.13954, saving model to bestCheckPoint.pth\n115s - loss:  2.07757 - acc: 0.56818 - val_loss: 2.13954 - val_acc: 0.50125\nEpoch 7/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00007: val_loss improved from 2.13954 to 2.03198, saving model to bestCheckPoint.pth\n115s - loss:  1.91981 - acc: 0.59596 - val_loss: 2.03198 - val_acc: 0.50125\nEpoch 8/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00008: val_loss improved from 2.03198 to 1.93979, saving model to bestCheckPoint.pth\n115s - loss:  1.77968 - acc: 0.62184 - val_loss: 1.93979 - val_acc: 0.52130\nEpoch 9/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00009: val_loss improved from 1.93979 to 1.89224, saving model to bestCheckPoint.pth\n115s - loss:  1.64971 - acc: 0.64899 - val_loss: 1.89224 - val_acc: 0.52381\nEpoch 10/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00010: val_loss improved from 1.89224 to 1.82040, saving model to bestCheckPoint.pth\n115s - loss:  1.52176 - acc: 0.69255 - val_loss: 1.82040 - val_acc: 0.54887\nEpoch 11/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00011: val_loss improved from 1.82040 to 1.75385, saving model to bestCheckPoint.pth\n115s - loss:  1.41810 - acc: 0.73737 - val_loss: 1.75385 - val_acc: 0.55138\nEpoch 12/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00012: val_loss improved from 1.75385 to 1.69486, saving model to bestCheckPoint.pth\n115s - loss:  1.31153 - acc: 0.76831 - val_loss: 1.69486 - val_acc: 0.56642\nEpoch 13/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.88s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00013: val_loss improved from 1.69486 to 1.65781, saving model to bestCheckPoint.pth\n116s - loss:  1.20156 - acc: 0.80366 - val_loss: 1.65781 - val_acc: 0.56892\nEpoch 14/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00014: val_loss improved from 1.65781 to 1.63986, saving model to bestCheckPoint.pth\n116s - loss:  1.12314 - acc: 0.81692 - val_loss: 1.63986 - val_acc: 0.56642\nEpoch 15/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00015: val_loss improved from 1.63986 to 1.58913, saving model to bestCheckPoint.pth\n115s - loss:  1.04079 - acc: 0.83081 - val_loss: 1.58913 - val_acc: 0.57143\nEpoch 16/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00016: val_loss did not improve\n112s - loss:  0.96651 - acc: 0.85164 - val_loss: 1.60008 - val_acc: 0.57895\nEpoch 17/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00017: val_loss improved from 1.58913 to 1.56784, saving model to bestCheckPoint.pth\n115s - loss:  0.90829 - acc: 0.86048 - val_loss: 1.56784 - val_acc: 0.56140\nEpoch 18/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00018: val_loss improved from 1.56784 to 1.52584, saving model to bestCheckPoint.pth\n115s - loss:  0.83874 - acc: 0.87816 - val_loss: 1.52584 - val_acc: 0.58647\nEpoch 19/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00019: val_loss improved from 1.52584 to 1.51972, saving model to bestCheckPoint.pth\n115s - loss:  0.77020 - acc: 0.88321 - val_loss: 1.51972 - val_acc: 0.57143\nEpoch 20/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00020: val_loss improved from 1.51972 to 1.50906, saving model to bestCheckPoint.pth\n115s - loss:  0.71778 - acc: 0.89205 - val_loss: 1.50906 - val_acc: 0.56642\nEpoch 21/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00021: val_loss improved from 1.50906 to 1.47910, saving model to bestCheckPoint.pth\n115s - loss:  0.66367 - acc: 0.90341 - val_loss: 1.47910 - val_acc: 0.56391\nEpoch 22/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00022: val_loss improved from 1.47910 to 1.47438, saving model to bestCheckPoint.pth\n116s - loss:  0.62451 - acc: 0.90593 - val_loss: 1.47438 - val_acc: 0.57393\nEpoch 23/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00023: val_loss improved from 1.47438 to 1.46942, saving model to bestCheckPoint.pth\n115s - loss:  0.58548 - acc: 0.91414 - val_loss: 1.46942 - val_acc: 0.55890\nEpoch 24/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00024: val_loss improved from 1.46942 to 1.46354, saving model to bestCheckPoint.pth\n115s - loss:  0.54074 - acc: 0.91982 - val_loss: 1.46354 - val_acc: 0.56642\nEpoch 25/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00025: val_loss improved from 1.46354 to 1.44495, saving model to bestCheckPoint.pth\n116s - loss:  0.50459 - acc: 0.92487 - val_loss: 1.44495 - val_acc: 0.57143\nEpoch 26/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00026: val_loss did not improve\n112s - loss:  0.46139 - acc: 0.93119 - val_loss: 1.44809 - val_acc: 0.57143\nEpoch 27/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00027: val_loss improved from 1.44495 to 1.43085, saving model to bestCheckPoint.pth\n115s - loss:  0.44310 - acc: 0.93687 - val_loss: 1.43085 - val_acc: 0.57143\nEpoch 28/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00028: val_loss did not improve\n112s - loss:  0.41336 - acc: 0.94318 - val_loss: 1.43860 - val_acc: 0.57143\nEpoch 29/30\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 00029: val_loss did not improve\n112s - loss:  0.38705 - acc: 0.94760 - val_loss: 1.43330 - val_acc: 0.55388\n","output_type":"stream"}]},{"cell_type":"code","source":"## 저장되어있는 best checkpoint load\n\nbest_model = torch.load(os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))['model'] \nbest_model.load_state_dict(torch.load(os.path.join(dataset_dir, scenario + '/checkpoint/bestCheckpoint.pth'))['model_state_dict'])  ","metadata":{"execution":{"iopub.status.busy":"2023-04-07T07:55:59.587374Z","iopub.execute_input":"2023-04-07T07:55:59.587761Z","iopub.status.idle":"2023-04-07T07:56:01.532339Z","shell.execute_reply.started":"2023-04-07T07:55:59.587722Z","shell.execute_reply":"2023-04-07T07:56:01.531155Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"#test \nimport math\n\nbatch_size = 1\n\ntest_dataset = DeepSense6G(dataset_dir, split=scenario, flag=2)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\ncorrect = 0\ntotal = 0\ntotal_results = []\ngt = []\n\ndef top_k (gts, preds, k) :\n    correct = 0\n\n    for i in range(len(preds)) :\n        gt = gts[i]\n        pred = preds[i]\n        correct += int(gt.item() in pred[:k])\n    \n    print(scenario, 'top', k, 'accuracy', 100 * correct / len(preds))\n\ndef mse (gts, preds) :\n    mse = 0\n\n    for i in range(len(preds)) :\n        gt = gts[i].item()\n        pred = preds[i][0]\n        mse += (gt-pred)**2\n    \n    print(scenario, 'mse', mse/len(preds))\n\nwith torch.no_grad() :\n    model.eval()\n    for img, bi in test_loader :\n        pred = best_model(img.cuda())\n        sorted_result_idx = np.flip(np.array(np.argsort(pred.cpu())[0]))\n        top3 = sorted_result_idx[:3]\n        total_results.append(top3)\n        gt.append(bi)\n\ntop_k(gt, total_results, 1)\ntop_k(gt, total_results, 2)\ntop_k(gt, total_results, 3)\nmse(gt, total_results)","metadata":{"execution":{"iopub.status.busy":"2023-04-07T07:56:01.534526Z","iopub.execute_input":"2023-04-07T07:56:01.537264Z","iopub.status.idle":"2023-04-07T07:56:17.556407Z","shell.execute_reply.started":"2023-04-07T07:56:01.537233Z","shell.execute_reply":"2023-04-07T07:56:17.555179Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Scenario5 top 1 accuracy 63.722397476340696\nScenario5 top 2 accuracy 83.91167192429022\nScenario5 top 3 accuracy 94.00630914826499\nScenario5 mse 0.9779179810725552\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}